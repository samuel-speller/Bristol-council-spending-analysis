{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "In recent years there have been significant reductions in local authority funding,\n",
    "and budgets have been reduced accordingly.\n",
    "Cutting spending on preventative measures like early help in schools, quality of life\n",
    "improvements for elderly and disabled residents, could lead to having to spend\n",
    "more later to fix more severe problems as a result.\n",
    "Using a sample spending dataset from a local authority, design a model to test this\n",
    "theory. (Look for ‘Spend over £500’ open data).\n",
    "Remember:\n",
    "* What question are you answering?\n",
    "* If you had an answer, what would it look like?\n",
    "* What data would be relevant?\n",
    "* What are the principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from natsort import natsorted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a web scraper to download and combine .csv files.\n",
    "I found a page on Bristol council's website which contained more £500 spend data from a longer period (since 2010).\n",
    "However it was provided in separate .csv files by month.\n",
    "\n",
    "the council website was returning a 403 error when it was being scraped. So we need to set up a fake agent to make the website think\n",
    "the requests are coming from a real user rather than a scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've changed this cell to markdown to stop it running ever time i use run all\n",
    "\n",
    "# dummy header to make the website think a real user is requesting the data\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'}\n",
    "\n",
    "# URL of the webpage containing CSV files\n",
    "url = 'https://www.bristol.gov.uk/council-and-mayor/council-spending-and-performance/spending-over-500'\n",
    "\n",
    "# Download the webpage content\n",
    "response = requests.get(url, headers=HEADERS)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# by inspecting the webpage in chrome I found that all the links to the\n",
    "# csv files had a 'type' so we can tell the scraper to look for this type.\n",
    "# Find all links with a type attribute of 'text/csv' and extract their URLs\n",
    "links = []\n",
    "for link in soup.find_all('a', type='text/csv'):\n",
    "    links.append(urljoin(url, link.get('href')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all CSV files and save them in the csv_folder\n",
    "# set dummy variable used for naming the csv files\n",
    "i=0\n",
    "# iterate over the list of links and download each csv file\n",
    "for link in links:\n",
    "    try:\n",
    "        file_response = requests.get(link, headers=HEADERS)\n",
    "    \n",
    "        # save the file to the csv_files folder\n",
    "        with open(f\"csv_files original scrape/{str(i)}.csv\", \"wb\") as f:\n",
    "            f.write(file_response.content)\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading CSV file from {link}: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean the csv files\n",
    "The files don't share the same formatting (unfotunately!) so we need to clean them up before combining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory containing the CSV files\n",
    "DIRECTORY = \"csv_files/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samuelspeller/Documents/GitHub/Bristol-council-spending-analysis\n"
     ]
    }
   ],
   "source": [
    "# rename the csv files to show month and date.\n",
    "# the files were downloaded in month order so we can set the start month and year\n",
    "# and then decrease each in a descending order.\n",
    "start_month = 2\n",
    "start_year = 2023\n",
    "\n",
    "# sort the list of files in ascending order (natsort can sort string numbers properly)\n",
    "wd = os.getcwd()\n",
    "print(wd)\n",
    "\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "file_list = natsorted(file_list)\n",
    "\n",
    "# iterate over the csv files\n",
    "for filename in file_list:\n",
    "    os.rename(DIRECTORY + filename, DIRECTORY + f'{start_year}-{start_month}.csv')\n",
    "    start_month = start_month - 1\n",
    "    if start_month == 0:\n",
    "        start_month = 12\n",
    "        start_year = start_year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the csv files\n",
    "for filename in os.listdir(DIRECTORY):\n",
    "    if filename.endswith('.csv'):\n",
    "        # read the CSV file into a pandas DataFrame \n",
    "        df = pd.read_csv(os.path.join(DIRECTORY, filename), encoding='latin', on_bad_lines='warn')\n",
    "\n",
    "        # dictionary of column names to rename\n",
    "        rename_columns = {\n",
    "            'Name': 'Supplier', \n",
    "            'Description Line 1': 'Description 1',\n",
    "            'Description Line 2': 'Description 2',\n",
    "            'Description Line 3': 'Description 3'\n",
    "        }\n",
    "        # rename columns\n",
    "        for key, value in rename_columns.items():\n",
    "            if key in df.columns:\n",
    "                df.rename(columns={key:value}, inplace = True)\n",
    "\n",
    "        # some of the data doesn't contain transaction dates so lets at least add\n",
    "        # the month and year from the file name.\n",
    "        \n",
    "        if 'Pay Date' not in df.columns:\n",
    "            date = os.path.splitext(filename)\n",
    "            df.insert(2, 'Pay Date', date[0])\n",
    "\n",
    "        # some of the files have transaction numbers and some don't.\n",
    "        # lets drop all of the transaction/ref columns\n",
    "        # create a list of column names to delete\n",
    "        del_columns = ['Body', 'Body Name', 'Transaction Number', 'Ref', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 0']\n",
    "        for name in del_columns:\n",
    "            if name in df.columns:\n",
    "                df = df.drop(columns=[name])\n",
    "        \n",
    "        # add description 3 column if it's missing\n",
    "        #if 'Description 3' not in df.columns:\n",
    "        #    df.insert(5, 'Description 3', ' ' )\n",
    "\n",
    "        # look for all the files which don't have the correct amount of columns\n",
    "        if len(df.columns) != 6:\n",
    "            print(filename)\n",
    "        \n",
    "        # save the modified DataFrame back to the CSV file\n",
    "        df.to_csv(os.path.join(DIRECTORY, filename), index=False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to check that all the csv files have the same column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all columns match!\n"
     ]
    }
   ],
   "source": [
    "# Define path to the directory containing CSV files\n",
    "DIRECTORY = 'csv_files/'\n",
    "csv_files = sorted(os.listdir(DIRECTORY))\n",
    "\n",
    "# Read the first CSV file in the list to get the column names\n",
    "first_file = pd.read_csv(os.path.join(DIRECTORY, csv_files[0]))\n",
    "column_names = first_file.columns.tolist()\n",
    "\n",
    "# Loop through the rest of the CSV files and check if they have the same columns\n",
    "for file in csv_files[1:]:\n",
    "    next_file = pd.read_csv(os.path.join(DIRECTORY, file))\n",
    "    if next_file.columns.tolist() != column_names:\n",
    "        print(f'Column names in {format(file)} do not match')\n",
    "        exit()\n",
    "\n",
    "print('all columns match!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the csv files\n",
    "Now we can combine all the csv files so we have one large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the directory containing the CSV files\n",
    "DIRECTORY = \"csv_files/\"\n",
    "\n",
    "# create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# loop through the CSV files in the directory and append their dataframes to the list\n",
    "for filename in os.listdir(DIRECTORY):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(DIRECTORY, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# concatenate the dataframes in the list into a single dataframe\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# write the combined dataframe to a new CSV file\n",
    "combined_df.to_csv('bristol_spending_data.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lots of weird characters present (probably due to encoding issues)\n",
    "Lets remove these characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters we want to remove\n",
    "chars_to_remove = ['Â', 'Ã']\n",
    "\n",
    "# define a function to replace letters with an empty string\n",
    "def clean_text(x, chars_to_remove):\n",
    "    if isinstance(x, str):\n",
    "        for char in chars_to_remove:\n",
    "            x = x.replace(char, '')\n",
    "        return x\n",
    "    else: \n",
    "        return x\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('bristol_spending_data.csv')\n",
    "\n",
    "# apply the lambda function to each element in the DataFrame using applymap()\n",
    "df_cleaned = df.applymap(lambda x: clean_text(x, chars_to_remove))\n",
    "df_cleaned.to_csv('bristol_spending_data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \" characters from the amounts column\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('bristol_spending_data.csv')\n",
    "\n",
    "df['Amount'] = df['Amount'].replace('\"', '')\n",
    "\n",
    "df.to_csv('bristol_spending_data_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# make sure all negative signs are at the start of numbers in amounts\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# read csv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mbristol_spending_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m df\u001b[39m.\u001b[39;49mnum\u001b[39m.\u001b[39mmask(df\u001b[39m.\u001b[39mnum\u001b[39m.\u001b[39mstr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39misin([\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m]), df\u001b[39m.\u001b[39mnum\u001b[39m.\u001b[39mstr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcat(df\u001b[39m.\u001b[39mnum\u001b[39m.\u001b[39mstr[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[39m# df.to_csv('bristol_spending_data_final.csv', index=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'num'"
     ]
    }
   ],
   "source": [
    "# make sure all negative signs are at the start of numbers in amounts\n",
    "\n",
    "# read csv\n",
    "df = pd.read_csv('bristol_spending_data.csv')\n",
    "\n",
    "df.num.mask(df.num.str[-1].isin(['-','+']), df.num.str[-1].str.cat(df.num.str[:-1])).astype('float')\n",
    "\n",
    "\n",
    "\n",
    "# df.to_csv('bristol_spending_data_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
