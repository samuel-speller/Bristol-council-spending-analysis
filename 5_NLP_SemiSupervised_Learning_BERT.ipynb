{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi Supervised Learning - BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I maually labelled some of the transactions in the data with categories that I obtained from the council's budget. The plan was to then use these labels to train the algorithm to label the unlabelled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samuelspeller/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for downloading BERT\n",
    "# pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#for finding most similar text vectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#regular expressoin toolkit\n",
    "import re\n",
    "\n",
    "#NLP toolkits\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#for plotting transaction categories later\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker # for formatting major units on x-y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the semi-labelled data and write to a pkl file\n",
    "\n",
    "# df = pd.read_excel('./spending_data/bristol_spending_data_final_semi_labeled.xlsx')\n",
    "\n",
    "# # set non numeric values to n/a with errors=coerce\n",
    "# df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "\n",
    "# # convert the date to a datetime object\n",
    "# df['Pay Date']= pd.to_datetime(df['Pay Date'], format='%d/%m/%Y')\n",
    "\n",
    "# # check the df\n",
    "# print(df.info())\n",
    "\n",
    "# # Write to pickle pickle file\n",
    "# with open('./pkl_data/bristol_spending_data_semi_labelled.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(df, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1022713 entries, 0 to 1022712\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count    Dtype         \n",
      "---  ------         --------------    -----         \n",
      " 0   Supplier       1022713 non-null  object        \n",
      " 1   Amount         1022712 non-null  float64       \n",
      " 2   Pay Date       1022713 non-null  datetime64[ns]\n",
      " 3   Description 1  1022704 non-null  object        \n",
      " 4   Description 2  1018731 non-null  object        \n",
      " 5   Description 3  834026 non-null   object        \n",
      " 6   label          45276 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(2), object(4)\n",
      "memory usage: 54.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "# Load the semi-labelled dataset   \n",
    "with open('./pkl_data/bristol_spending_data_semi_labelled.pkl', 'rb') as pickle_file:\n",
    "    df = pickle.load(pickle_file)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into labelled and unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a dictionary containing the labels with descriptions\n",
    "labels = {1:'Education, Learning and Skills Improvement',\n",
    "          2:'Safeguarding vulnerable adults and children',\n",
    "          3:'Social care and support for adults including the elderly',\n",
    "          4:'Support for voluntary groups',\n",
    "          5:'Public Health',\n",
    "          6:'pupil premium (education)',\n",
    "          7:'Museums and Culture',\n",
    "          8:'Property',\n",
    "          9:'Community Services Parks and open spaces',\n",
    "          10:'Housing and Landlord Services',\n",
    "          11:'early years education',\n",
    "          12:'SEN'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Supplier   Amount   Pay Date  \\\n",
      "0                                 MUSO LIMITED    600.0 2013-03-28   \n",
      "1                        ARNOLFINI GALLERY LTD   5000.0 2013-03-25   \n",
      "2                             SHOW OF STRENGTH   8000.0 2013-03-25   \n",
      "3                          THE TOBACCO FACTORY  10000.0 2013-03-25   \n",
      "4  BRISTOL INTERNATIONAL JAZZ & BLUES FESTIVAL   2500.0 2013-03-18   \n",
      "\n",
      "                Description 1               Description 2  \\\n",
      "0                FEES PAYABLE  \"ARTS, EVENTS & FESTIVALS\"   \n",
      "1  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
      "2  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
      "3  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
      "4              GRANTS PAYABLE  \"ARTS, EVENTS & FESTIVALS\"   \n",
      "\n",
      "                Description 3  label  \n",
      "0            ARTS & FESTIVALS    7.0  \n",
      "1                   ARNOLFINI    7.0  \n",
      "2            SHOW OF STRENGTH    7.0  \n",
      "3  TOBACCO FACTORY ARTS TRUST    7.0  \n",
      "4          NEIGHBOURHOOD ARTS    7.0  \n",
      "                  Supplier   Amount   Pay Date  \\\n",
      "64  CREATIVE YOUTH NETWORK  2059.75 2013-03-27   \n",
      "65  CREATIVE YOUTH NETWORK  2059.75 2013-01-03   \n",
      "66      ALIPORT COMMERCIAL  5210.00 2013-03-28   \n",
      "67       ALVIS CONTRACTING   650.00 2013-03-28   \n",
      "68       ALVIS CONTRACTING  3385.00 2013-03-28   \n",
      "\n",
      "                             Description 1                     Description 2  \\\n",
      "64                            FEES PAYABLE  \"P D, PARTNERSHIPS & LOCALITIES\"   \n",
      "65                            FEES PAYABLE  \"P D, PARTNERSHIPS & LOCALITIES\"   \n",
      "66               RESPONSE MAINT - DEPT USE    \"PARKS, ESTATES, CREMS & CEMS\"   \n",
      "67     RESP MAINT - BUILDING PRACTICE ONLY    \"PARKS, ESTATES, CREMS & CEMS\"   \n",
      "68  PAYMENT TO CONTRACTORS - VARIABLE SUMS    \"PARKS, ESTATES, CREMS & CEMS\"   \n",
      "\n",
      "                Description 3  label  \n",
      "64  225 SEN TARGETED PROJECTS    NaN  \n",
      "65  225 SEN TARGETED PROJECTS    NaN  \n",
      "66      CREMS & CEMS RENEWALS    NaN  \n",
      "67                    ESTATES    NaN  \n",
      "68                    ESTATES    NaN  \n",
      "\n",
      "\n",
      "the number of labelled transactions: 45276\n",
      "\n",
      "\n",
      "the number of unlabelled transactions: 977437\n"
     ]
    }
   ],
   "source": [
    "# we want to train on the labelled data so lets pull all the transactions with labels\n",
    "\n",
    "# the dataframe has some 0 values and some na. Lets convert all the 0 to na\n",
    "df['label'] = df['label'].replace(0, np.nan)\n",
    "\n",
    "# filter rows where the label is NaN, e.g. not labelled\n",
    "labelled_df = df.loc[df['label'].notna()]\n",
    "unlabelled_df = df.loc[df['label'].isna()]\n",
    "\n",
    "\n",
    "print(labelled_df.head())\n",
    "print(unlabelled_df.head())\n",
    "\n",
    "print(f'\\n\\nthe number of labelled transactions: {len(labelled_df)}')\n",
    "print(f'\\n\\nthe number of unlabelled transactions: {len(unlabelled_df)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine descriptions\n",
    "\n",
    "lets combine the supplier name and the descriptions so we can tokenize and train on all of them at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t7/n_c5tq1n0h985pbhlhf2w0c80000gn/T/ipykernel_60083/914057943.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labelled_df['text_data'] = labelled_df[columns_to_combine].apply(lambda x: ' '.join(y for y in x.dropna().astype(str) if 'REDACTED' not in y), axis=1)\n",
      "/var/folders/t7/n_c5tq1n0h985pbhlhf2w0c80000gn/T/ipykernel_60083/914057943.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unlabelled_df['text_data'] = unlabelled_df[columns_to_combine].apply(lambda x: ' '.join(y for y in x.dropna().astype(str) if 'REDACTED' not in y), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# create a new column containing all the text data\n",
    "# make sure there is a space inbetween the different column text data.\n",
    "# ignore a value if it is NaN or 'REDACTED' as we don't want the model to train on these.\n",
    "\n",
    "columns_to_combine = ['Supplier', 'Description 1', 'Description 2', 'Description 3' ]\n",
    "\n",
    "labelled_df['text_data'] = labelled_df[columns_to_combine].apply(lambda x: ' '.join(y for y in x.dropna().astype(str) if 'REDACTED' not in y), axis=1)\n",
    "\n",
    "unlabelled_df['text_data'] = unlabelled_df[columns_to_combine].apply(lambda x: ' '.join(y for y in x.dropna().astype(str) if 'REDACTED' not in y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Pay Date</th>\n",
       "      <th>Description 1</th>\n",
       "      <th>Description 2</th>\n",
       "      <th>Description 3</th>\n",
       "      <th>label</th>\n",
       "      <th>text_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MUSO LIMITED</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2013-03-28</td>\n",
       "      <td>FEES PAYABLE</td>\n",
       "      <td>\"ARTS, EVENTS &amp; FESTIVALS\"</td>\n",
       "      <td>ARTS &amp; FESTIVALS</td>\n",
       "      <td>7.0</td>\n",
       "      <td>MUSO LIMITED FEES PAYABLE \"ARTS, EVENTS &amp; FEST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARNOLFINI GALLERY LTD</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>PAYMENTS TO OTHER AGENCIES</td>\n",
       "      <td>\"ARTS, EVENTS &amp; FESTIVALS\"</td>\n",
       "      <td>ARNOLFINI</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ARNOLFINI GALLERY LTD PAYMENTS TO OTHER AGENCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOW OF STRENGTH</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>PAYMENTS TO OTHER AGENCIES</td>\n",
       "      <td>\"ARTS, EVENTS &amp; FESTIVALS\"</td>\n",
       "      <td>SHOW OF STRENGTH</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SHOW OF STRENGTH PAYMENTS TO OTHER AGENCIES \"A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE TOBACCO FACTORY</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>PAYMENTS TO OTHER AGENCIES</td>\n",
       "      <td>\"ARTS, EVENTS &amp; FESTIVALS\"</td>\n",
       "      <td>TOBACCO FACTORY ARTS TRUST</td>\n",
       "      <td>7.0</td>\n",
       "      <td>THE TOBACCO FACTORY PAYMENTS TO OTHER AGENCIES...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRISTOL INTERNATIONAL JAZZ &amp; BLUES FESTIVAL</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2013-03-18</td>\n",
       "      <td>GRANTS PAYABLE</td>\n",
       "      <td>\"ARTS, EVENTS &amp; FESTIVALS\"</td>\n",
       "      <td>NEIGHBOURHOOD ARTS</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BRISTOL INTERNATIONAL JAZZ &amp; BLUES FESTIVAL GR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Supplier   Amount   Pay Date  \\\n",
       "0                                 MUSO LIMITED    600.0 2013-03-28   \n",
       "1                        ARNOLFINI GALLERY LTD   5000.0 2013-03-25   \n",
       "2                             SHOW OF STRENGTH   8000.0 2013-03-25   \n",
       "3                          THE TOBACCO FACTORY  10000.0 2013-03-25   \n",
       "4  BRISTOL INTERNATIONAL JAZZ & BLUES FESTIVAL   2500.0 2013-03-18   \n",
       "\n",
       "                Description 1               Description 2  \\\n",
       "0                FEES PAYABLE  \"ARTS, EVENTS & FESTIVALS\"   \n",
       "1  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
       "2  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
       "3  PAYMENTS TO OTHER AGENCIES  \"ARTS, EVENTS & FESTIVALS\"   \n",
       "4              GRANTS PAYABLE  \"ARTS, EVENTS & FESTIVALS\"   \n",
       "\n",
       "                Description 3  label  \\\n",
       "0            ARTS & FESTIVALS    7.0   \n",
       "1                   ARNOLFINI    7.0   \n",
       "2            SHOW OF STRENGTH    7.0   \n",
       "3  TOBACCO FACTORY ARTS TRUST    7.0   \n",
       "4          NEIGHBOURHOOD ARTS    7.0   \n",
       "\n",
       "                                           text_data  \n",
       "0  MUSO LIMITED FEES PAYABLE \"ARTS, EVENTS & FEST...  \n",
       "1  ARNOLFINI GALLERY LTD PAYMENTS TO OTHER AGENCI...  \n",
       "2  SHOW OF STRENGTH PAYMENTS TO OTHER AGENCIES \"A...  \n",
       "3  THE TOBACCO FACTORY PAYMENTS TO OTHER AGENCIES...  \n",
       "4  BRISTOL INTERNATIONAL JAZZ & BLUES FESTIVAL GR...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create word embeddings for labeled data\n",
    "Download and then use the pre-trained BERT model to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_BERT(text):\n",
    "    '''\n",
    "    A function to clean and tokenize text so it is ready to be inputted into BERT\n",
    "    '''\n",
    "\n",
    "    # Convert words to lower case.\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and numbers. This also removes the dates \n",
    "    # which are not important in classifying expenses\n",
    "    text = re.sub(r'[^\\w\\s]|https?://\\S+|www\\.\\S+|https?:/\\S+|[^\\x00-\\x7F]+|\\d+', '', str(text).strip())\n",
    "  \n",
    "    # Tokenise \n",
    "    text_list = word_tokenize(text)\n",
    "    result = ' '.join(text_list)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean our text data\n",
    "text_raw = labelled_df['text_data']\n",
    "text_BERT = text_raw.apply(lambda x: clean_text_BERT(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St George Health Centre Services - Supplies and Services to service users 03:NHS Health Checks  \n",
      "st george health centre services supplies and services to service users nhs health checks\n"
     ]
    }
   ],
   "source": [
    "# an example of the text data before and after cleaning\n",
    "print(text_raw[2000])\n",
    "print(text_BERT[2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea0e615426c493e864ee4dd92e2a7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1415 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # This may take some time to download and run.\n",
    "# # depending on the size of the input.\n",
    "# # I have saved the output using the cell below so it can be loaded quickly.\n",
    "\n",
    "# model = SentenceTransformer('paraphrase-mpnet-base-v2') \n",
    "# bert_input = text_BERT.tolist()\n",
    "# embeddings = model.encode(bert_input, show_progress_bar = True)\n",
    "# embedding_BERT = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save these embeddings to a numpy file\n",
    "# np.save('./pkl_data/labelled_data_embedding.npy', embedding_BERT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1147997 ,  0.00622684, -0.06120515, ..., -0.01737143,\n",
       "         0.16032901, -0.01618893],\n",
       "       [-0.05237475,  0.2965644 , -0.03495542, ..., -0.00776623,\n",
       "         0.12089074,  0.03460617],\n",
       "       [-0.13074368,  0.17108506, -0.05069165, ...,  0.01171169,\n",
       "         0.10542176, -0.04691478],\n",
       "       ...,\n",
       "       [-0.10476775,  0.19025211,  0.00164859, ..., -0.12478687,\n",
       "        -0.25964585, -0.03215555],\n",
       "       [-0.10476775,  0.19025211,  0.00164859, ..., -0.12478687,\n",
       "        -0.25964585, -0.03215555],\n",
       "       [-0.10476775,  0.19025211,  0.00164859, ..., -0.12478687,\n",
       "        -0.25964585, -0.03215555]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the embeddings from the pkl file\n",
    "embedding_BERT = np.load('./pkl_data/labelled_data_embedding.npy', allow_pickle = True)\n",
    "\n",
    "embedding_BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114800</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>-0.061205</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.119211</td>\n",
       "      <td>-0.133504</td>\n",
       "      <td>0.078139</td>\n",
       "      <td>-0.041612</td>\n",
       "      <td>0.057181</td>\n",
       "      <td>0.107018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>-0.055724</td>\n",
       "      <td>0.046353</td>\n",
       "      <td>-0.081037</td>\n",
       "      <td>-0.058252</td>\n",
       "      <td>-0.214004</td>\n",
       "      <td>-0.102968</td>\n",
       "      <td>-0.017371</td>\n",
       "      <td>0.160329</td>\n",
       "      <td>-0.016189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052375</td>\n",
       "      <td>0.296564</td>\n",
       "      <td>-0.034955</td>\n",
       "      <td>0.221045</td>\n",
       "      <td>0.061655</td>\n",
       "      <td>-0.072989</td>\n",
       "      <td>0.238213</td>\n",
       "      <td>-0.012476</td>\n",
       "      <td>0.121805</td>\n",
       "      <td>0.046962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042820</td>\n",
       "      <td>-0.027373</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>-0.009347</td>\n",
       "      <td>-0.035258</td>\n",
       "      <td>-0.218472</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>0.120891</td>\n",
       "      <td>0.034606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.130744</td>\n",
       "      <td>0.171085</td>\n",
       "      <td>-0.050692</td>\n",
       "      <td>0.192037</td>\n",
       "      <td>0.058402</td>\n",
       "      <td>-0.046011</td>\n",
       "      <td>-0.000910</td>\n",
       "      <td>0.078297</td>\n",
       "      <td>0.136332</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089419</td>\n",
       "      <td>-0.066612</td>\n",
       "      <td>0.238528</td>\n",
       "      <td>0.071327</td>\n",
       "      <td>-0.037926</td>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.012964</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.105422</td>\n",
       "      <td>-0.046915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.111276</td>\n",
       "      <td>0.301693</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.242109</td>\n",
       "      <td>-0.036181</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>0.122539</td>\n",
       "      <td>0.095006</td>\n",
       "      <td>0.153006</td>\n",
       "      <td>0.060218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065611</td>\n",
       "      <td>-0.048483</td>\n",
       "      <td>-0.030131</td>\n",
       "      <td>-0.006278</td>\n",
       "      <td>0.049288</td>\n",
       "      <td>0.232537</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>-0.004122</td>\n",
       "      <td>0.042453</td>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.114618</td>\n",
       "      <td>0.306195</td>\n",
       "      <td>-0.072638</td>\n",
       "      <td>0.144114</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>-0.048989</td>\n",
       "      <td>-0.135876</td>\n",
       "      <td>0.098075</td>\n",
       "      <td>0.017136</td>\n",
       "      <td>0.106360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>-0.037302</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>-0.107279</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>-0.126855</td>\n",
       "      <td>-0.091941</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.152749</td>\n",
       "      <td>-0.019689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.114800  0.006227 -0.061205  0.055468  0.119211 -0.133504  0.078139   \n",
       "1 -0.052375  0.296564 -0.034955  0.221045  0.061655 -0.072989  0.238213   \n",
       "2 -0.130744  0.171085 -0.050692  0.192037  0.058402 -0.046011 -0.000910   \n",
       "3 -0.111276  0.301693  0.041094  0.242109 -0.036181  0.022725  0.122539   \n",
       "4 -0.114618  0.306195 -0.072638  0.144114  0.027658 -0.048989 -0.135876   \n",
       "\n",
       "        7         8         9    ...       758       759       760       761  \\\n",
       "0 -0.041612  0.057181  0.107018  ...  0.015894 -0.055724  0.046353 -0.081037   \n",
       "1 -0.012476  0.121805  0.046962  ...  0.042820 -0.027373  0.052239 -0.009347   \n",
       "2  0.078297  0.136332  0.062710  ...  0.089419 -0.066612  0.238528  0.071327   \n",
       "3  0.095006  0.153006  0.060218  ... -0.065611 -0.048483 -0.030131 -0.006278   \n",
       "4  0.098075  0.017136  0.106360  ...  0.096182 -0.037302 -0.001019 -0.107279   \n",
       "\n",
       "        762       763       764       765       766       767  \n",
       "0 -0.058252 -0.214004 -0.102968 -0.017371  0.160329 -0.016189  \n",
       "1 -0.035258 -0.218472 -0.011269 -0.007766  0.120891  0.034606  \n",
       "2 -0.037926  0.030003  0.012964  0.011712  0.105422 -0.046915  \n",
       "3  0.049288  0.232537  0.008580 -0.004122  0.042453  0.046353  \n",
       "4  0.011401 -0.126855 -0.091941  0.026467  0.152749 -0.019689  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # have a look at the word embeddings\n",
    "\n",
    "# df_embedding_bert = pd.DataFrame(embeddings)\n",
    "# df_embedding_bert.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create word embeddings for unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ae085125e647c89052558686b81811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first create a test sample (as it takes a long time to compute this)\n",
    "# this will create a new dataframe using the first 200 rows \n",
    "test_unlabelled_df = unlabelled_df.head(500)\n",
    "\n",
    "# Load texts\n",
    "text_test_raw = test_unlabelled_df['text_data']\n",
    "\n",
    "# Apply data cleaning function as for training data\n",
    "text_test_BERT = text_test_raw.apply(lambda x: clean_text_BERT(x))\n",
    "\n",
    "\n",
    "# Apply BERT embedding\n",
    "bert_input_test = text_test_BERT.tolist()\n",
    "model = SentenceTransformer('paraphrase-mpnet-base-v2') \n",
    "embeddings_test = model.encode(bert_input_test, show_progress_bar = True)\n",
    "embedding_BERT_test = np.array(embeddings_test)\n",
    "\n",
    "df_embedding_bert_test = pd.DataFrame(embeddings_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair unseen data with the most similar training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       8164\n",
      "1       8164\n",
      "2       8519\n",
      "3      30465\n",
      "4       8320\n",
      "       ...  \n",
      "495    27141\n",
      "496    44958\n",
      "497    27144\n",
      "498     4940\n",
      "499     4940\n",
      "Length: 500, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the most similar word embedding with unseen data in the training data\n",
    "\n",
    "similarity_new_data = cosine_similarity(embedding_BERT_test, embedding_BERT)\n",
    "similarity_df = pd.DataFrame(similarity_new_data)\n",
    "\n",
    "# Returns index for most similar embedding\n",
    "# See first column of the output dataframe below\n",
    "index_similarity = similarity_df.idxmax(axis = 1)\n",
    "\n",
    "print(index_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unseen_transaction</th>\n",
       "      <th>matched_transaction</th>\n",
       "      <th>matched_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>New Delight Enterprises Ltd Services - Fees an...</td>\n",
       "      <td>Drawn In Bristol Services - Fees and Charges M...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Kennet Equipment Leasing Ltd Equipment - Purch...</td>\n",
       "      <td>KINGKRAFT LTD EQUIPMENT, FURNITURE &amp; MATERIALS...</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Cooltech Environmental Engineering Ltd Service...</td>\n",
       "      <td>Bristol Blue Glass (Sw) Ltd Services - Fees an...</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Pattersons (Bristol) Limited Catering 100 Temp...</td>\n",
       "      <td>Pegasus Catering Ltd Catering 15:Smokefree Bri...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Pattersons (Bristol) Limited Catering 100 Temp...</td>\n",
       "      <td>Pegasus Catering Ltd Catering 15:Smokefree Bri...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    unseen_transaction  \\\n",
       "495  New Delight Enterprises Ltd Services - Fees an...   \n",
       "496  Kennet Equipment Leasing Ltd Equipment - Purch...   \n",
       "497  Cooltech Environmental Engineering Ltd Service...   \n",
       "498  Pattersons (Bristol) Limited Catering 100 Temp...   \n",
       "499  Pattersons (Bristol) Limited Catering 100 Temp...   \n",
       "\n",
       "                                   matched_transaction  matched_class  \n",
       "495  Drawn In Bristol Services - Fees and Charges M...           13.0  \n",
       "496  KINGKRAFT LTD EQUIPMENT, FURNITURE & MATERIALS...           12.0  \n",
       "497  Bristol Blue Glass (Sw) Ltd Services - Fees an...           13.0  \n",
       "498  Pegasus Catering Ltd Catering 15:Smokefree Bri...            5.0  \n",
       "499  Pegasus Catering Ltd Catering 15:Smokefree Bri...            5.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return dataframe for most similar embedding/transactions in training dataframe\n",
    "data_inspect = labelled_df.iloc[index_similarity, :].reset_index(drop = True)\n",
    "\n",
    "unseen_verbatim = text_test_raw.reset_index(drop = True)\n",
    "matched_verbatim = data_inspect['text_data']\n",
    "label = data_inspect['label']\n",
    "\n",
    "d_output = {\n",
    "            'unseen_transaction': unseen_verbatim,\n",
    "            'matched_transaction': matched_verbatim, \n",
    "            'matched_class': label\n",
    "            \n",
    "            }\n",
    "\n",
    "d_output_df = pd.DataFrame.from_dict(d_output)\n",
    "d_output_df.tail()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "* save the word embeddings so we don't need to compute them every time.\n",
    "* train a random set of unlabelled data.\n",
    "* train all the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
